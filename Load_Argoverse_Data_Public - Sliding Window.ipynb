{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"../new_train/\"\n",
    "val_path = \"../new_val_in/\"\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset  = ArgoverseDataset(data_path=new_path)\n",
    "val_dataset = ArgoverseDataset(data_path=val_path)\n",
    "#print((val_dataset[0]))\n",
    "#print(len(train_dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 1\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in'],]) for scene in batch]\n",
    "    out = [numpy.dstack([scene['p_out'], scene['v_out']]) for scene in batch]\n",
    "#     inp = [scene['p_in'] for scene in batch]\n",
    "#     out = [scene['p_out'] for scene in batch]\n",
    "#     print(inp.size)\n",
    "#     print(\"gap\")\n",
    "#     print(out.size)\n",
    "    #inp = np.concatenate((inp, out), axis=0)\n",
    "    inp = torch.FloatTensor(inp)\n",
    "#     print(inp.shape)\n",
    "#     print(\"after\")\n",
    "#     print(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def val_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = [numpy.dstack([scene['p_in'], scene['v_in']]) for scene in batch]\n",
    "    inp = torch.LongTensor(inp)\n",
    "    return inp\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = False, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True, nonlinearity='relu')\n",
    "        #print(self.rnn)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        #print(hidden.shape)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden\n",
    "        \"\"\"\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        print(x)\n",
    "        #print(\"gap\")\n",
    "        #print(h0.shape)\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "        \"\"\"\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_a_histogram(sample_batch, agent_id, xPos, yPos, xVel, yVel):\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    #agent_sz = inp.size(1)\n",
    "    \n",
    "    for i in range(batch_sz):\n",
    "        #hist_data_xPos = np.zeros((60,19));\n",
    "        #hist_data_yPos = np.zeros((60,19));\n",
    "        #hist_data_xVel = np.zeros((60,19));\n",
    "        hist_data_yVel = np.zeros((60,19));\n",
    "        \n",
    "        for j in range(60):\n",
    "            #hist_data_xPos[j] = (inp[i, j,:,0])\n",
    "            #hist_data_yPos[j] = (inp[i, j,:,1])\n",
    "            #hist_data_xVel[j] = (inp[i, j,:,2])\n",
    "            hist_data_yVel[j] = (inp[i, j,:,3])\n",
    "            \n",
    "        for j in range(len(hist_data_yVel)):\n",
    "            for k in range(len(hist_data_yVel[j])):\n",
    "                #xPos.append(hist_data_xPos[j][k])\n",
    "                #yPos.append(hist_data_yPos[j][k])\n",
    "                #xVel.append(hist_data_xVel[j][k])\n",
    "                yVel.append(hist_data_yVel[j][k])\n",
    "    \n",
    "    \"\"\"\n",
    "    hist_data_xPos = np.zeros((60,19));\n",
    "    hist_data_yPos = np.zeros((60,19));\n",
    "    hist_data_xVel = np.zeros((60,19));\n",
    "    hist_data_yVel = np.zeros((60,19));\n",
    "    \n",
    "    for i in range(60):\n",
    "        hist_data_xPos[i] = (inp[0, i,:,0])\n",
    "        hist_data_yPos[i] = (inp[0, i,:,1])\n",
    "        hist_data_xVel[i] = (inp[0, i,:,2])\n",
    "        hist_data_yVel[i] = (inp[0, i,:,3])\n",
    "    \n",
    "    xPos = np.zeros(60*19)\n",
    "    for i in range(len(hist_data_xPos)):\n",
    "        for j in range(len(hist_data_xPos[i])):\n",
    "            xPos[i*19+j] = hist_data_xPos[i][j]\n",
    "    \n",
    "    #hist_data_xPos = hist_data_xPos.flatten()\n",
    "    hist_data_yVel = hist_data_yPos.flatten()\n",
    "    hist_data_xPos = hist_data_xVel.flatten()\n",
    "    hist_data_yVel = hist_data_yVel.flatten()\n",
    "    #print(xPos)\n",
    "    \n",
    "    n,bins,patches = plt.hist(x=xPos,bins='auto',alpha=0.7,rwidth=0.85)\n",
    "    plt.grid(axis='y',alpha=0.75)\n",
    "    maxfreq = n.max()\n",
    "    plt.ylim(ymax=np.ceil(maxfreq/10) * 10 if maxfreq % 10 else maxfreq + 10)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "0   tensor(360815.4062, grad_fn=<MseLossBackward>)\n",
      "100   tensor(195597.2344, grad_fn=<MseLossBackward>)\n",
      "200   tensor(222831.7344, grad_fn=<MseLossBackward>)\n",
      "300   tensor(515626.7812, grad_fn=<MseLossBackward>)\n",
      "400   tensor(597851.3125, grad_fn=<MseLossBackward>)\n",
      "500   tensor(426031.3125, grad_fn=<MseLossBackward>)\n",
      "600   tensor(112337.4062, grad_fn=<MseLossBackward>)\n",
      "700   tensor(228332.1094, grad_fn=<MseLossBackward>)\n",
      "800   tensor(86813.7578, grad_fn=<MseLossBackward>)\n",
      "900   tensor(240729.3281, grad_fn=<MseLossBackward>)\n",
      "1000   tensor(594589.6250, grad_fn=<MseLossBackward>)\n",
      "1100   tensor(62695.9688, grad_fn=<MseLossBackward>)\n",
      "1200   tensor(196395.8906, grad_fn=<MseLossBackward>)\n",
      "1300   tensor(201950.0156, grad_fn=<MseLossBackward>)\n",
      "1400   tensor(578082., grad_fn=<MseLossBackward>)\n",
      "1500   tensor(77448.2812, grad_fn=<MseLossBackward>)\n",
      "1600   tensor(298774.3750, grad_fn=<MseLossBackward>)\n",
      "1700   tensor(579002.8750, grad_fn=<MseLossBackward>)\n",
      "1800   tensor(70584.0078, grad_fn=<MseLossBackward>)\n",
      "1900   tensor(207199.4844, grad_fn=<MseLossBackward>)\n",
      "2000   tensor(215630.5469, grad_fn=<MseLossBackward>)\n",
      "2100   tensor(487334.3438, grad_fn=<MseLossBackward>)\n",
      "2200   tensor(409131.2812, grad_fn=<MseLossBackward>)\n",
      "2300   tensor(228829.5156, grad_fn=<MseLossBackward>)\n",
      "2400   tensor(378193.5312, grad_fn=<MseLossBackward>)\n",
      "2500   tensor(183305.5781, grad_fn=<MseLossBackward>)\n",
      "2600   tensor(271488.8125, grad_fn=<MseLossBackward>)\n",
      "2700   tensor(1090757.2500, grad_fn=<MseLossBackward>)\n",
      "2800   tensor(145893.9219, grad_fn=<MseLossBackward>)\n",
      "2900   tensor(539328.8125, grad_fn=<MseLossBackward>)\n",
      "3000   tensor(1549308.6250, grad_fn=<MseLossBackward>)\n",
      "3100   tensor(142198.4844, grad_fn=<MseLossBackward>)\n",
      "3200   tensor(335010.3750, grad_fn=<MseLossBackward>)\n",
      "3300   tensor(182923.4062, grad_fn=<MseLossBackward>)\n",
      "3400   tensor(1591005.1250, grad_fn=<MseLossBackward>)\n",
      "3500   tensor(69833.0078, grad_fn=<MseLossBackward>)\n",
      "3600   tensor(295238.9688, grad_fn=<MseLossBackward>)\n",
      "3700   tensor(1317198.5000, grad_fn=<MseLossBackward>)\n",
      "3800   tensor(350941.5938, grad_fn=<MseLossBackward>)\n",
      "3900   tensor(193492.5000, grad_fn=<MseLossBackward>)\n",
      "4000   tensor(162861.5469, grad_fn=<MseLossBackward>)\n",
      "4100   tensor(80357.2422, grad_fn=<MseLossBackward>)\n",
      "4200   tensor(315375.7812, grad_fn=<MseLossBackward>)\n",
      "4300   tensor(444133.3438, grad_fn=<MseLossBackward>)\n",
      "4400   tensor(528581.5000, grad_fn=<MseLossBackward>)\n",
      "4500   tensor(258976.9844, grad_fn=<MseLossBackward>)\n",
      "4600   tensor(187140.2500, grad_fn=<MseLossBackward>)\n",
      "4700   tensor(139810.5156, grad_fn=<MseLossBackward>)\n",
      "4800   tensor(225154.0156, grad_fn=<MseLossBackward>)\n",
      "4900   tensor(423593.3125, grad_fn=<MseLossBackward>)\n",
      "5000   tensor(165329.8281, grad_fn=<MseLossBackward>)\n",
      "5100   tensor(357119.1250, grad_fn=<MseLossBackward>)\n",
      "5200   tensor(507621.0625, grad_fn=<MseLossBackward>)\n",
      "5300   tensor(252725.9531, grad_fn=<MseLossBackward>)\n",
      "5400   tensor(192972.2500, grad_fn=<MseLossBackward>)\n",
      "5500   tensor(221599.0469, grad_fn=<MseLossBackward>)\n",
      "5600   tensor(929914.2500, grad_fn=<MseLossBackward>)\n",
      "5700   tensor(598585.4375, grad_fn=<MseLossBackward>)\n",
      "5800   tensor(91341.8125, grad_fn=<MseLossBackward>)\n",
      "5900   tensor(173601.5781, grad_fn=<MseLossBackward>)\n",
      "6000   tensor(214107.7031, grad_fn=<MseLossBackward>)\n",
      "6100   tensor(472829.7812, grad_fn=<MseLossBackward>)\n",
      "6200   tensor(605409.8750, grad_fn=<MseLossBackward>)\n",
      "6300   tensor(111886.1094, grad_fn=<MseLossBackward>)\n",
      "6400   tensor(268137.0312, grad_fn=<MseLossBackward>)\n",
      "6500   tensor(701175.8125, grad_fn=<MseLossBackward>)\n",
      "6600   tensor(172004.4844, grad_fn=<MseLossBackward>)\n",
      "6700   tensor(114207.3750, grad_fn=<MseLossBackward>)\n",
      "6800   tensor(289831.2500, grad_fn=<MseLossBackward>)\n",
      "6900   tensor(269019.2500, grad_fn=<MseLossBackward>)\n",
      "7000   tensor(509782.9375, grad_fn=<MseLossBackward>)\n",
      "7100   tensor(239787.6562, grad_fn=<MseLossBackward>)\n",
      "7200   tensor(369559.1250, grad_fn=<MseLossBackward>)\n",
      "7300   tensor(95520., grad_fn=<MseLossBackward>)\n",
      "7400   tensor(373237.0938, grad_fn=<MseLossBackward>)\n",
      "7500   tensor(205332.2812, grad_fn=<MseLossBackward>)\n",
      "7600   tensor(68756.4141, grad_fn=<MseLossBackward>)\n",
      "7700   tensor(359613.0938, grad_fn=<MseLossBackward>)\n",
      "7800   tensor(413039.6875, grad_fn=<MseLossBackward>)\n",
      "7900   tensor(185633.4062, grad_fn=<MseLossBackward>)\n",
      "8000   tensor(237191.0156, grad_fn=<MseLossBackward>)\n",
      "8100   tensor(230366.8281, grad_fn=<MseLossBackward>)\n",
      "8200   tensor(240605.0625, grad_fn=<MseLossBackward>)\n",
      "8300   tensor(165706.4219, grad_fn=<MseLossBackward>)\n",
      "8400   tensor(125876.8594, grad_fn=<MseLossBackward>)\n",
      "8500   tensor(488323.8125, grad_fn=<MseLossBackward>)\n",
      "8600   tensor(257482.0781, grad_fn=<MseLossBackward>)\n",
      "8700   tensor(269437.8438, grad_fn=<MseLossBackward>)\n",
      "8800   tensor(264773.8125, grad_fn=<MseLossBackward>)\n",
      "8900   tensor(1060180.1250, grad_fn=<MseLossBackward>)\n",
      "9000   tensor(814032.6250, grad_fn=<MseLossBackward>)\n",
      "9100   tensor(423920.9688, grad_fn=<MseLossBackward>)\n",
      "9200   tensor(802590., grad_fn=<MseLossBackward>)\n",
      "9300   tensor(241008.5000, grad_fn=<MseLossBackward>)\n",
      "9400   tensor(172294.0312, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "agent_id = 0\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "device = \"cpu\"\n",
    "input_dim = 4    # input dimension\n",
    "hidden_dim = 100  # hidden layer dimension\n",
    "layer_dim = 1     # number of hidden layers\n",
    "output_dim = 4   # output dimension\n",
    "\n",
    "n_epochs = 100\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "#model = RNNModel(input_dim, output_dim, hidden_dim, layer_dim).to(device)\n",
    "model = RNNModel(input_size=input_dim, output_size=output_dim, hidden_dim=12, n_layers=1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,momentum=momentum)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "model.train()\n",
    "print(\"test\")\n",
    "for i_batch, sample_batch in enumerate(train_loader):\n",
    "#     print(\"test\")\n",
    "    inp, out = sample_batch\n",
    "    #make_a_histogram(sample_batch, agent_id, xPos, yPos, xVel, yVel)\n",
    "    \"\"\"TODO:\n",
    "      Deep learning model\n",
    "      training routine\n",
    "    \"\"\"\n",
    "    inp, out = inp.to(device), out.to(device)\n",
    "    optimizer.zero_grad()\n",
    "#     print(inp[0].shape)\n",
    "    outList = torch.empty((1,60,30,4))\n",
    "\n",
    "    for i in range(30):\n",
    "        output,hidden = model(inp[0].float())\n",
    "        output = output.reshape(1,60,19,4)\n",
    "#         print(\"output\",output[0,:,18].shape)\n",
    "        \n",
    "        outList[0,:,i] = output[0,:,18].detach()\n",
    "#         for j in range(60):\n",
    "\n",
    "#             outList[0][j][i] = output[0][j][18].detach().numpy()\n",
    "#         for k in range(60):\n",
    "#             for j in range(1,19):\n",
    "#                 inp[0][k][j-1] = inp[0][k][j]\n",
    "#             inp[0][k][18] = output[0][k][18]\n",
    "        inp[0] = torch.roll(inp[0,:],-1,dims=1)\n",
    "        inp[0,:,18] = output[0,:,18]\n",
    "\n",
    "#     outList = torch.FloatTensor(outList)\n",
    "    outList.requires_grad=True\n",
    "\n",
    "#     print(out.shape)\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(outList, out)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#     show_sample_batch(sample_batch, agent_id)\n",
    "    if i_batch % 100 == 0:\n",
    "        print (i_batch, \" \",loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
