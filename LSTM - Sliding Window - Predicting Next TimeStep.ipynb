{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\"\"\"Change to the data folder\"\"\"\n",
    "new_path = \"../new_train/\"\n",
    "val_path = \"../new_val_in/\"\n",
    "\n",
    "# number of sequences in each dataset\n",
    "# train:205942  val:3200 test: 36272 \n",
    "# sequences sampled at 10HZ rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, data_path: str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.pkl_list = glob(os.path.join(self.data_path, '*'))\n",
    "        self.pkl_list.sort()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pkl_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        pkl_path = self.pkl_list[idx]\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "#         data['p_in']-= numpy.mean(data['p_in'])\n",
    "        if self.transform:\n",
    "            min_max_scaler= preprocessing.MinMaxScaler()\n",
    "            for i in range(60):\n",
    "                data['p_in'][i] = min_max_scaler.fit_transform(data['p_in'][i])\n",
    "                data['v_in'][i] = min_max_scaler.fit_transform(data['v_in'][i])\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "# intialize a dataset\n",
    "train_dataset  = ArgoverseDataset(data_path=new_path,transform=True)\n",
    "val_dataset = ArgoverseDataset(data_path=val_path,transform=True)\n",
    "#print((val_dataset[0]))\n",
    "#print(len(train_dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a loader to enable batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 1\n",
    "\n",
    "def my_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "#     if(len(str(maxVal)) > 3):\n",
    "#         print(len(maxVal))\n",
    "#     print(\"maxStringLength\",len(str(maxVal)))\n",
    "#     print(\"k   \",len(maxVal))\n",
    "    \n",
    "    inp = []\n",
    "    out = []\n",
    "    numbRows = 1000\n",
    "    for scene in batch:\n",
    "#         print(scene['p_in'])\n",
    "        lanes = numpy.zeros((numbRows,19,3))\n",
    "        lane_norm = numpy.zeros((numbRows,19,3))\n",
    "        pIn = vIn = numpy.zeros((numbRows,19,3))\n",
    "#         lane_norm =[0,0]\n",
    "        lengthLane = min(numbRows,len(scene['lane']))\n",
    "        pIn[:len(scene['p_in']),:,:2] = scene['p_in']\n",
    "        vIn[:len(scene['v_in']),:,:2] = scene['v_in']\n",
    "        lanes[:lengthLane,0,:3] = scene['lane'][:lengthLane,:]\n",
    "        lane_norm[:lengthLane,0,:3] = scene['lane_norm'] [:lengthLane,:]\n",
    "        inp.append(numpy.dstack([pIn,vIn,lanes,lane_norm]))\n",
    "        out.append(numpy.dstack([scene['p_out'], scene['v_out']]))\n",
    "        \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    out = torch.FloatTensor(out)\n",
    "    return [inp, out]\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz, shuffle = True, collate_fn=my_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def val_collate(batch):\n",
    "    \"\"\" collate lists of samples into batches, create [ batch_sz x agent_sz x seq_len x feature] \"\"\"\n",
    "    inp = []\n",
    "    numbRows = 1000\n",
    "    for scene in batch:\n",
    "#         print(scene['p_in'])\n",
    "        lanes = numpy.zeros((numbRows,19,3))\n",
    "        lane_norm = numpy.zeros((numbRows,19,3))\n",
    "        pIn = vIn = numpy.zeros((numbRows,19,3))\n",
    "#         lane_norm =[0,0]\n",
    "        lengthLane = min(numbRows,len(scene['lane']))\n",
    "        pIn[:len(scene['p_in']),:,:2] = scene['p_in']\n",
    "        vIn[:len(scene['v_in']),:,:2] = scene['v_in']\n",
    "        lanes[:lengthLane,0,:3] = scene['lane'][:lengthLane,:]\n",
    "        lane_norm[:lengthLane,0,:3] = scene['lane_norm'] [:lengthLane,:]\n",
    "        inp.append(numpy.dstack([pIn,vIn,lanes,lane_norm]))\n",
    "        \n",
    "    inp = torch.FloatTensor(inp)\n",
    "    return inp\n",
    "\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz, shuffle = True, collate_fn=val_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "#         # Number of hidden dimensions\n",
    "#         self.hidden_dim = hidden_dim\n",
    "        \n",
    "#         # Number of hidden layers\n",
    "#         self.n_layers = n_layers\n",
    "        \n",
    "#         # RNN\n",
    "#         self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True, nonlinearity='relu')\n",
    "#         #print(self.rnn)\n",
    "        \n",
    "#         # Readout layer\n",
    "#         self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         batch_size = x.size(0)\n",
    "        \n",
    "#         hidden = self.init_hidden(batch_size)\n",
    "#         #print(hidden.shape)\n",
    "#         out, hidden = self.rnn(x, hidden)\n",
    "#         out = out.contiguous().view(-1, self.hidden_dim)\n",
    "#         out = self.fc(out)\n",
    "        \n",
    "#         return out, hidden\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True,dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    def forward(self, x,previous):\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        x = x.to(device)\n",
    "        h0 = 0\n",
    "        c0 = 0\n",
    "        if(previous == 1):\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim,device=device).requires_grad_()\n",
    "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim,device=device).requires_grad_()\n",
    "        else:\n",
    "            hn,cn = previous\n",
    "            h0 = hn\n",
    "            c0 = cn\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "#         print(\"forward outshape\",out.shape)\n",
    "        return out,(hn,cn)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim,device=torch.device(\"cuda:0\"))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_a_histogram(sample_batch, agent_id, xPos, yPos, xVel, yVel):\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    #agent_sz = inp.size(1)\n",
    "    \n",
    "    for i in range(batch_sz):\n",
    "        #hist_data_xPos = np.zeros((60,19));\n",
    "        #hist_data_yPos = np.zeros((60,19));\n",
    "        #hist_data_xVel = np.zeros((60,19));\n",
    "        hist_data_yVel = np.zeros((60,19));\n",
    "        \n",
    "        for j in range(60):\n",
    "            #hist_data_xPos[j] = (inp[i, j,:,0])\n",
    "            #hist_data_yPos[j] = (inp[i, j,:,1])\n",
    "            #hist_data_xVel[j] = (inp[i, j,:,2])\n",
    "            hist_data_yVel[j] = (inp[i, j,:,3])\n",
    "            \n",
    "        for j in range(len(hist_data_yVel)):\n",
    "            for k in range(len(hist_data_yVel[j])):\n",
    "                #xPos.append(hist_data_xPos[j][k])\n",
    "                #yPos.append(hist_data_yPos[j][k])\n",
    "                #xVel.append(hist_data_xVel[j][k])\n",
    "                yVel.append(hist_data_yVel[j][k])\n",
    "    \n",
    "    \"\"\"\n",
    "    hist_data_xPos = np.zeros((60,19));\n",
    "    hist_data_yPos = np.zeros((60,19));\n",
    "    hist_data_xVel = np.zeros((60,19));\n",
    "    hist_data_yVel = np.zeros((60,19));\n",
    "    \n",
    "    for i in range(60):\n",
    "        hist_data_xPos[i] = (inp[0, i,:,0])\n",
    "        hist_data_yPos[i] = (inp[0, i,:,1])\n",
    "        hist_data_xVel[i] = (inp[0, i,:,2])\n",
    "        hist_data_yVel[i] = (inp[0, i,:,3])\n",
    "    \n",
    "    xPos = np.zeros(60*19)\n",
    "    for i in range(len(hist_data_xPos)):\n",
    "        for j in range(len(hist_data_xPos[i])):\n",
    "            xPos[i*19+j] = hist_data_xPos[i][j]\n",
    "    \n",
    "    #hist_data_xPos = hist_data_xPos.flatten()\n",
    "    hist_data_yVel = hist_data_yPos.flatten()\n",
    "    hist_data_xPos = hist_data_xVel.flatten()\n",
    "    hist_data_yVel = hist_data_yVel.flatten()\n",
    "    #print(xPos)\n",
    "    \n",
    "    n,bins,patches = plt.hist(x=xPos,bins='auto',alpha=0.7,rwidth=0.85)\n",
    "    plt.grid(axis='y',alpha=0.75)\n",
    "    maxfreq = n.max()\n",
    "    plt.ylim(ymax=np.ceil(maxfreq/10) * 10 if maxfreq % 10 else maxfreq + 10)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_batch(sample_batch, agent_id):\n",
    "    \"\"\"visualize the trajectory for a batch of samples with a randon agent\"\"\"\n",
    "    inp, out = sample_batch\n",
    "    batch_sz = inp.size(0)\n",
    "    agent_sz = inp.size(1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,batch_sz, figsize=(15, 3), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    axs = axs.ravel()   \n",
    "    for i in range(batch_sz):\n",
    "        axs[i].xaxis.set_ticks([])\n",
    "        axs[i].yaxis.set_ticks([])\n",
    "        \n",
    "        # first two feature dimensions are (x,y) positions\n",
    "        axs[i].scatter(inp[i, agent_id,:,0], inp[i, agent_id,:,1])\n",
    "        axs[i].scatter(out[i, agent_id,:,0], out[i, agent_id,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the batch of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "batch #:  0  avg loss (past 100):  4940.574739583333\n",
      "batch #:  100  avg loss (past 100):  90542.32669864909\n",
      "batch #:  200  avg loss (past 100):  15113.822676340738\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "agent_id = 0\n",
    "learning_rate = 50\n",
    "momentum = 0.1\n",
    "device = torch.device(\"cuda:0\")\n",
    "input_dim = 12    # input dimension\n",
    "hidden_dim = 1  # hidden layer dimension\n",
    "layer_dim = 10     # number of hidden layers\n",
    "output_dim = 4   # output dimension\n",
    "\n",
    "n_epochs = 5\n",
    "lr=0.01\n",
    "\n",
    "# Define Loss, Optimizer\n",
    "#model = RNNModel(input_dim, output_dim, hidden_dim, layer_dim).to(device)\n",
    "model = RNNModel(input_size=input_dim, output_size=output_dim, hidden_dim=12, n_layers=1)\n",
    "model.load_state_dict(torch.load('./sliding3epoch.pth'))\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate,lr_decay=0.00000001)\n",
    "model.eval()\n",
    "\n",
    "    \n",
    "model.train()\n",
    "\n",
    "print(\"test\")\n",
    "newOut = torch.zeros((1000,30,4))\n",
    "batch = []\n",
    "try:\n",
    "    for i_epoch in range(n_epochs):\n",
    "        for i_batch, sample_batch in enumerate(train_loader):\n",
    "        #     print(\"test\")\n",
    "            inp, out = sample_batch\n",
    "\n",
    "            oneTimeStep = out[0,:,0]\n",
    "            optimizer.zero_grad()\n",
    "            newOut[:60,:,:] = out[0]\n",
    "            initHidden = 1\n",
    "            scaled_loss = 0\n",
    "        #     print(inp)\n",
    "            for i in range(30):\n",
    "\n",
    "                output,hidden = model(inp[0].float().cuda(),initHidden)\n",
    "\n",
    "                initHidden = hidden\n",
    "                hn,cn = initHidden\n",
    "\n",
    "                x = inp[0,:60,:,:4]\n",
    "                x = torch.roll(x,-1,dims=1)\n",
    "                inp[0,:60,:19,:4] = x\n",
    "                inp[0,:60,18,:4] = out[0,:60,i,:]\n",
    "\n",
    "    #             import random\n",
    "    #             x = random.uniform(0, 1)\n",
    "    #             if x < 0.5:\n",
    "    #                 continue\n",
    "                loss = nn.MSELoss()\n",
    "                loss = loss(output.cuda(),newOut[:,i,:].cuda())\n",
    "                loss.backward(retain_graph=True)\n",
    "                scaled_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            batch.append(scaled_loss/30)\n",
    "\n",
    "            if i_batch % 100 == 0:\n",
    "                print(\"batch #: \",i_batch ,\" avg loss (past 100): \",mean(batch))\n",
    "                batch = []\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(model.state_dict(), './sliding3epoch.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './sliding3epoch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 4 required positional arguments: 'input_size', 'output_size', 'hidden_dim', and 'n_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-3057e8243bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtestModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtestModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtestModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 4 required positional arguments: 'input_size', 'output_size', 'hidden_dim', and 'n_layers'"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "testModel = RNNModel()\n",
    "testModel.load_state_dict(torch.load('path'))\n",
    "testModel = testModel.to(device)\n",
    "testModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21', 'v22', 'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'v29', 'v30', 'v31', 'v32', 'v33', 'v34', 'v35', 'v36', 'v37', 'v38', 'v39', 'v40', 'v41', 'v42', 'v43', 'v44', 'v45', 'v46', 'v47', 'v48', 'v49', 'v50', 'v51', 'v52', 'v53', 'v54', 'v55', 'v56', 'v57', 'v58', 'v59', 'v60']\n",
      "test\n",
      "batch #:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-63c3fe9d7cdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#     print(len(sample_batch[1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#     print(sample_batch[0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscene_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#     print(agent_id, track_id)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "save_file = \"submissionsliding.csv\"\n",
    "\n",
    "input_dim = 12    # input dimension\n",
    "hidden_dim = 1  # hidden layer dimension\n",
    "layer_dim = 10     # number of hidden layers\n",
    "output_dim = 4   # output dimension\n",
    "\n",
    "header = [\"ID\"]\n",
    "header += [\"v\"+str(x) for x in range(1, 61)]\n",
    "print(header)\n",
    "\n",
    "with open(save_file, 'w') as f:\n",
    "    f.write(\",\".join(header)+\"\\n\")\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "testmodel = RNNModel(input_size=input_dim, output_size=output_dim, hidden_dim=12, n_layers=1)\n",
    "testmodel.load_state_dict(torch.load('sliding3epoch.pth'))\n",
    "testmodel.to(device)\n",
    "testmodel.eval()\n",
    "\n",
    "full_out = []\n",
    "newOut = torch.zeros((1000,30,4))\n",
    "batch = []\n",
    "print(\"test\")\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    if i_batch % 10 == 0:\n",
    "        print(\"batch #: \", i_batch)\n",
    "#     print(len(sample_batch[1]))\n",
    "#     print(sample_batch[0].shape)\n",
    "    inp, scene_idx, agent_ids, track_ids = sample_batch\n",
    "#     print(agent_id, track_id)\n",
    "\n",
    "    batch_size = inp.shape[0]\n",
    "\n",
    "    bool_loc = np.stack([np.squeeze(track_id) == np.repeat(ag_id,60) for ag_id, track_id in zip(agent_ids, track_ids)])\n",
    "#     print(\"bool_loc shape: \", bool_loc.shape)\n",
    "\n",
    "\n",
    "    initHidden = 1\n",
    "    scaled_loss = 0\n",
    "#     print(inp)\n",
    "    full_out = []\n",
    "    for i in range(30):\n",
    "\n",
    "        output,hidden = testmodel(inp[0].float().cuda(),initHidden)\n",
    "\n",
    "        initHidden = hidden\n",
    "        hn,cn = initHidden\n",
    "        full_out.append(output)\n",
    "\n",
    "    out = torch.stack(full_out)\n",
    "#     print(out.shape)\n",
    "    \n",
    "#     inp = inp.transpose(1,2)\n",
    "#     inp = inp.reshape(batch_size, 19, -1)\n",
    "#     inp = inp.to(device)\n",
    "#     out = testmodel(inp.float())\n",
    "#     out = out.transpose(0, 1)\n",
    "#     out = out.reshape(batch_size, 30, 60, 2)\n",
    "#     out = out.transpose(1,2)\n",
    "#     out = out.reshape(batch_size, 60, -1)\n",
    "#     out = out.reshape(batch_size, )\n",
    "#     out = out.to(\"cpu\")\n",
    "    \n",
    "    \n",
    "#     print(\"out shape before: \", out.shape)\n",
    "    out = out.transpose(0,1)\n",
    "    out = out[:60, :, :2]\n",
    "    out = out.reshape(60, -1)\n",
    "    out = out[bool_loc]\n",
    "#     print(type(out))\n",
    "#     print(\"out shape after: \", out.shape)\n",
    "#     full_out.append(out)\n",
    "#     print(type(scene_idx))\n",
    "#     print(\",\".join(out.detach().cpu().numpy().astype(int).astype(str)[0]))\n",
    "#     fin_out = np.concatenate((scene_idx.reshape(-1,1), out.detach().cpu().numpy().astype(int)), axis=1)\n",
    "    with open(save_file, \"a\") as f:\n",
    "        for row, scene_num in zip(out.detach().cpu().numpy().astype(int).astype(str), scene_idx):\n",
    "            f.write(str(scene_num)+\",\"+\",\".join(row)+\"\\n\")\n",
    "#         np.savetxt(f, fin_out, fmt=\"%cd\",delimiter=\",\", newline=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
